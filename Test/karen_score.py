# karen_score.py
# Usage:
#   python karen_score.py
#   python karen_score.py "C:\path\to\your\audio.m4a"

import os, sys, json, time, math
from dataclasses import dataclass, asdict

import numpy as np
import librosa
import librosa.display

# ------------ é…ç½®åŒºï¼ˆä½ å¯ä»¥éšæ—¶æ”¹ï¼‰ ------------
DEFAULT_AUDIO = r"C:\Users\Regina Sun\Documents\GitHub\Sound-Power\TestAudioInput\1.m4a"

SR = 16000               # ç»Ÿä¸€é‡‡æ ·ç‡
FRAME_HOP = 0.02         # 20ms hop
FRAME_LEN = 0.04         # 40ms window
HOP_LENGTH = int(SR * FRAME_HOP)
N_FFT = 2048

# Karen çš„â€œç¤¾ä¼šåè§â€æƒé‡ï¼ˆå¯è¿­ä»£è°ƒå‚ï¼‰
# çº¿æ€§æ‰“åˆ†åèµ° sigmoid â†’ 0~1
WEIGHTS = {
    "authority": {
        "f0_mean": -0.45,
        "f0_std": -0.10,
        "loudness_db": 0.35,
        "pause_ratio": -0.10,          # åŸ -0.30 â†’ é™ä½æƒ©ç½šï¼Œäº¤ç»™ç»†åˆ†ç‰¹å¾
        "pause_long_ratio": 0.28,      # é•¿åœé¡¿åŠ åˆ†ï¼ˆèŠ‚å¥è‡ªä¿¡/æƒå¨ï¼‰
        "filler_like_ratio": -0.35,    # å¡«å……éŸ³å‡åˆ†ï¼ˆæ˜¾å¾—ä¸ç¨³ï¼‰
        "jitter": -0.20,
    },
    "trust": {
        "jitter": -0.28,               # ç•¥æ”¾æ¾
        "shimmer": -0.20,              # ç•¥æ”¾æ¾
        "clarity": 0.30,
        "speaking_rate_wps": 0.12,
        "noise_floor_db": -0.08,
        "filler_like_ratio": -0.30,    # å¡«å……éŸ³æŸä¼¤â€œå¯ä¿¡â€
        "pause_cv": -0.08              # èŠ‚å¥è¿‡åº¦å¿½å¿«å¿½æ…¢ä¼šé™ä½å¯ä¿¡
    },
    "clarity": {
        "clarity": 0.45,
        "spectral_rolloff": -0.05,
        "spectral_centroid": -0.05,
        "pause_micro_ratio": -0.08,    # å¾®åœé¡¿å¤ªå¤šå¯èƒ½å‰²è£‚æ¸…æ™°åº¦
        "pause_ratio": -0.06
    },
    "fluency": {
        "pause_ratio": -0.18,          # æ€»åœé¡¿ä»å‡åˆ†ï¼Œä½†æ¯”åŸæ¥æ¸©å’Œ
        "speaking_rate_wps": 0.22,
        "f0_std": -0.05,
        "filler_like_ratio": -0.40,    # æµç•…åº¦é‡Œæœ€é‡æƒ©ç½šå¡«å……éŸ³
        "pause_long_ratio": 0.10       # æ°å½“é•¿åœé¡¿å¯è§†ä¸ºæœ‰èŠ‚å¥çš„â€œå‘¼å¸â€
    },
    "warmth": {     # äº²å’Œï¼šä¸­ä½éŸ³åŸŸã€å“åº¦ä¸è¿‡åº¦ã€æŠ–åŠ¨ä¸è¿‡å¤§
        "f0_mean": -0.12,
        "loudness_db": 0.10,
        "jitter": -0.08,
        "spectral_centroid": -0.10,
    }
}

BIASES = {  # æ¯ä¸ªç»´åº¦çš„åç½®
    "authority": 0.0,
    "trust": 0.0,
    "clarity": 0.0,
    "fluency": 0.0,
    "warmth": 0.0
}

PASS_RULE = {  # é€šè¿‡æ¡ä»¶ï¼ˆå¯æ”¹ï¼‰
    "authority": 0.55,
    "trust": 0.50,
    "clarity": 0.50,
    "fluency": 0.50,
}

# Karen çš„åˆ»è–„è¯­å¥è§¦å‘è§„åˆ™ï¼ˆç®€å•æ¨¡æ¿ï¼‰
KAREN_SNARKS = [
    # è´Ÿå‘è§¦å‘ï¼ˆé˜´é˜³æ€ªæ°”ï¼‰
    (lambda f,s: f["f0_mean"] > 200 and s["authority"] < 0.55, "High pitch gives me intern vibes."),
    (lambda f,s: f["filler_like_ratio"] > 0.04, "The little 'uh' and 'um'â€”like pebbles in your shoes."),
    (lambda f,s: f["pause_micro_ratio"] > 0.08 and s["fluency"] < 0.5, "Choppy rhythm. This isnâ€™t a buffering icon."),
    (lambda f,s: f["loudness_db"] < -18, "Speak up. This is a rally, not a library."),
    (lambda f,s: f["jitter"] > 0.03, "Your voice shakes like my iced latte."),
    (lambda f,s: s["trust"] < 0.4 and s["clarity"] < 0.5, "Hard to trust what I can barely parse."),
    # æ­£å‘è§¦å‘ï¼ˆçœŸé¼“åŠ±ï¼‰
    (lambda f,s: f["pause_long_ratio"] > 0.06 and s["authority"] > 0.6, "Those deliberate pauses? Presidential."),
    (lambda f,s: s["clarity"] > 0.65 and s["fluency"] > 0.6, "Clean articulation and steady flowâ€”your message lands."),
    (lambda f,s: s["warmth"] > 0.6 and s["trust"] > 0.55, "You sound like someone people want to follow, not just hear."),
    (lambda f,s: s["authority"] > 0.7, "Commanding presence. The room moves when you do.")
]


# ------------ å·¥å…·å‡½æ•° ------------
def contiguous_runs(mask):
    """è¿”å› (start_idx, end_idx) çš„è¿ç»­åŒºé—´ï¼Œendä¸ºåŒ…å«å¼"""
    runs = []
    i = 0
    n = len(mask)
    while i < n:
        if mask[i]:
            j = i
            while j+1 < n and mask[j+1]:
                j += 1
            runs.append((i, j))
            i = j + 1
        else:
            i += 1
    return runs

def estimate_pause_features(y, sr):
    """
    è¿”å›ï¼š
      pause_ratio         - é™éŸ³å æ¯”ï¼ˆæ€»åœé¡¿æ—¶é—´ / æ€»æ—¶é•¿ï¼‰
      pause_long_ratio    - é•¿åœé¡¿ï¼ˆâ‰¥350msï¼‰å æ¯”
      pause_micro_ratio   - å¾®åœé¡¿ï¼ˆ50â€“250msï¼‰å æ¯”
      filler_like_ratio   - ç–‘ä¼¼å¡«å……éŸ³å æ¯”ï¼ˆçŸ­ã€ä½èƒ½é‡ã€voicedã€f0ç¨³å®šï¼‰
      pause_cv            - åœé¡¿æ—¶é•¿å˜å¼‚ç³»æ•°ï¼ˆstd/meanï¼‰
    """
    # ---- å¸§åŒ– & èƒ½é‡ ----
    frame_len = int(sr * FRAME_LEN)      # e.g., 0.04s
    hop_len   = HOP_LENGTH               # e.g., 0.02s
    frames = librosa.util.frame(y, frame_length=frame_len, hop_length=hop_len)
    energy = np.mean(frames**2, axis=0)
    med = np.median(energy) + 1e-9
    thr = med * 0.25
    is_sil = energy < thr  # é™éŸ³æ©ç ï¼ˆåŸºäºç›¸å¯¹é˜ˆå€¼ï¼‰

    # ---- voicingï¼ˆç”¨ pyin voiced_prob è¿‘ä¼¼ï¼‰----
    # ç”¨æ›´é•¿ä¸€ç‚¹çš„çª—é¿å…â€œä¸¤å‘¨æœŸä¸è¶³â€çš„è­¦å‘Š
    pyin_frame_len = max(frame_len, int(sr * 0.06))
    f0, _, vprob = librosa.pyin(
        y,
        fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'),
        frame_length=pyin_frame_len, hop_length=hop_len
    )
    vprob = np.nan_to_num(vprob, nan=0.0)
    is_voiced = vprob > 0.6

    # f0 ç¨³å®šæ€§ï¼ˆä¾›å¡«å……éŸ³è¯†åˆ«ï¼‰
    f0_s = np.nan_to_num(f0, nan=0.0)
    f0_diff = np.abs(np.diff(f0_s))
    f0_diff = np.concatenate([[0.0], f0_diff])  # å¯¹é½é•¿åº¦
    f0_stable = f0_diff < 3.5  # Hz é˜ˆå€¼

    # ---- é•¿åº¦å¯¹é½ï¼ˆå…³é”®ä¿®å¤ç‚¹ï¼‰----
    n = min(len(is_sil), len(is_voiced), len(energy), len(f0_stable))
    is_sil     = is_sil[:n]
    is_voiced  = is_voiced[:n]
    f0_stable  = f0_stable[:n]
    energy     = energy[:n]
    low_energy = (energy < (med * 0.6))

    # ---- ç»Ÿè®¡è¿ç»­é™éŸ³æ®µï¼ˆå¾—åˆ° pause_dursï¼‰----
    runs = contiguous_runs(is_sil)  # [(start, end), ...], end åŒ…å«
    ms_per_hop = (hop_len / sr) * 1000.0

    def dur_ms(a, b):
        # åŒºé—´é•¿åº¦ = å¸§æ•° * hop æ—¶é—´ï¼›åŒ…å«å¼åŒºé—´ â†’ å¸§æ•° = (b - a + 1)
        return (b - a + 1) * ms_per_hop

    pause_durs = [dur_ms(a, b) for (a, b) in runs]  # â†â† è¿™é‡Œå°±å®šä¹‰äº†
    total_time_s = n * (hop_len / sr) + 1e-9
    pause_time_s = sum(pause_durs) / 1000.0

    # ---- åˆ†ç®±ï¼šlong / micro ----
    long_thr = 350.0   # ms
    micro_lo, micro_hi = 50.0, 250.0

    long_time_s  = sum(d for d in pause_durs if d >= long_thr) / 1000.0
    micro_time_s = sum(d for d in pause_durs if micro_lo <= d <= micro_hi) / 1000.0

    # ---- ç–‘ä¼¼å¡«å……éŸ³ï¼šéé™éŸ³ & Voiced & ä½èƒ½é‡ & f0ç¨³å®šï¼Œæ—¶é•¿ 80â€“300ms ----
    filler_mask = (~is_sil) & is_voiced & low_energy & f0_stable
    filler_runs = contiguous_runs(filler_mask)
    filler_time_s = 0.0
    for (a, b) in filler_runs:
        d = dur_ms(a, b)
        if 80.0 <= d <= 300.0:
            filler_time_s += d / 1000.0

    # ---- æ¯”ä¾‹ & å˜å¼‚ç³»æ•° ----
    pause_ratio        = float(pause_time_s  / total_time_s)
    pause_long_ratio   = float(long_time_s   / total_time_s)
    pause_micro_ratio  = float(micro_time_s  / total_time_s)
    filler_like_ratio  = float(filler_time_s / total_time_s)

    if len(pause_durs) >= 2 and np.mean(pause_durs) > 1e-9:
        pause_cv = float(np.std(pause_durs) / (np.mean(pause_durs) + 1e-9))
    else:
        pause_cv = 0.0

    return {
        "pause_ratio": pause_ratio,
        "pause_long_ratio": pause_long_ratio,
        "pause_micro_ratio": pause_micro_ratio,
        "filler_like_ratio": filler_like_ratio,
        "pause_cv": pause_cv
    }



def sigmoid(z):
    return 1. / (1. + np.exp(-z))

def rms_db(y):
    rms = np.sqrt(np.mean(np.square(y))) + 1e-9
    return 20 * np.log10(rms + 1e-12)

def moving_energy(y, frame_len, hop_len):
    frames = librosa.util.frame(y, frame_length=frame_len, hop_length=hop_len)
    return np.mean(frames**2, axis=0)

def estimate_pauses(energy, thresh_ratio=0.25):
    # ä½¿ç”¨èƒ½é‡ä¸­ä½æ•°çš„æ¯”ä¾‹é˜ˆå€¼ä¼°è®¡é™éŸ³/åœé¡¿
    med = np.median(energy) + 1e-9
    thr = med * thresh_ratio
    pauses = (energy < thr).astype(np.float32)
    return float(np.mean(pauses))

def estimate_speaking_rate(y, sr):
    # ç²—ç•¥ï¼šè¿‡é›¶ç‡+èƒ½é‡å³°è¿‘ä¼¼èŠ‚å¾‹ -> ä¼°ç®—æ¯ç§’â€œè¯â€ï¼ˆéå¸¸ç²—ç³™ï¼Œä½†å¯ç”¨æ¥é©±åŠ¨åˆ†æ•°ï¼‰
    zcr = librosa.feature.zero_crossing_rate(y, frame_length=int(sr*FRAME_LEN), hop_length=int(sr*FRAME_HOP))[0]
    # å³°å€¼æ£€æµ‹ï¼ˆèŠ‚å¾‹ proxyï¼‰
    peaks = (zcr[1:-1] > zcr[:-2]) & (zcr[1:-1] > zcr[2:]) & (zcr[1:-1] > (np.mean(zcr) + np.std(zcr)))
    approx_units_per_sec = peaks.sum() / (len(zcr)/ (sr*FRAME_HOP))
    # æ˜ å°„åˆ° 1.0~3.5 ä¹‹é—´
    return float(np.clip(approx_units_per_sec, 0.8, 4.0))

def spectral_features(y, sr):
    S = np.abs(librosa.stft(y, n_fft=N_FFT, hop_length=HOP_LENGTH))
    centroid = librosa.feature.spectral_centroid(S=S, sr=sr).mean()
    rolloff = librosa.feature.spectral_rolloff(S=S, sr=sr, roll_percent=0.85).mean()
    return float(centroid), float(rolloff)

def estimate_pitch(y, sr):
    f0, voiced_flag, voiced_prob = librosa.pyin(
        y,
        fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'),
        frame_length=int(sr * 0.06),   # â† ç”¨æ›´é•¿ä¸€ç‚¹çš„å¸§é•¿
        hop_length=HOP_LENGTH
    )
    f0 = f0[~np.isnan(f0)]
    if len(f0) == 0:
        return 0.0, 0.0, 0.0
    f0_mean = float(np.mean(f0))
    f0_std = float(np.std(f0))
    # è¿‘ä¼¼ jitter: ç›¸é‚»å¸§é¢‘ç‡å˜åŒ–çš„ç›¸å¯¹æŠ–åŠ¨
    df = np.abs(np.diff(f0))
    jitter = float(np.mean(df / (f0[:-1] + 1e-9))) if len(df) > 0 else 0.0
    return f0_mean, f0_std, jitter

def estimate_shimmer(y, sr):
    frame_len = int(sr*FRAME_LEN)
    hop_len = HOP_LENGTH
    frames = librosa.util.frame(y, frame_length=frame_len, hop_length=hop_len)
    # èƒ½é‡å¹…åº¦ï¼ˆé¿å…0ï¼‰
    amps = np.sqrt(np.mean(frames**2, axis=0)) + 1e-6
    da = np.abs(np.diff(amps)) / np.maximum(amps[:-1], 1e-6)
    # ç”¨ä¸­ä½æ•°æŠ—æç«¯å€¼ï¼Œå¹¶å‰ªè£åˆ°åˆç†èŒƒå›´
    sh = float(np.median(da))
    return float(np.clip(sh, 0.0, 0.3))


def estimate_noise_floor_db(y, sr):
    # ç®€å•ä¼°è®¡ï¼šå–èƒ½é‡æœ€ä½çš„ 10% å¸§çš„å‡å€¼ä½œä¸ºâ€œåº•å™ªâ€
    frame_len = int(sr*FRAME_LEN)
    hop_len = HOP_LENGTH
    frames = librosa.util.frame(y, frame_length=frame_len, hop_length=hop_len)
    e = np.mean(frames**2, axis=0)
    k = max(1, int(0.1 * len(e)))
    floor = np.mean(np.sort(e)[:k]) + 1e-12
    return 10 * np.log10(floor)

def estimate_clarity(y, sr):
    # è¯­éŸ³æ¸…æ™°åº¦ç²—ä¼°ï¼šè¿‡é›¶ç‡åä½ + é«˜é¢‘ä¸è¿‡åº¦ + èƒ½é‡é›†ä¸­
    zcr = librosa.feature.zero_crossing_rate(y, frame_length=int(sr*FRAME_LEN), hop_length=HOP_LENGTH)[0]
    centroid, rolloff = spectral_features(y, sr)
    # å½’ä¸€ï¼šç»™å‡º 0~1 çš„æ¸…æ™°åº¦ï¼ˆç»éªŒå¼ï¼‰
    zcr_norm = 1.0 - np.clip((zcr.mean() - 0.05) / 0.15, 0, 1)          # ZCRè¶Šé«˜ï¼Œè¶Šä¸æ¸…æ™° â†’ å–å
    cent_norm = 1.0 - np.clip((centroid - 2500) / 2500, 0, 1)           # è¿‡é«˜çš„è°±é‡å¿ƒâ†’åˆºè€³
    roll_norm = 1.0 - np.clip((rolloff - 6000) / 6000, 0, 1)            # è¿‡å¤šé«˜é¢‘å°¾å·´â†’æµ‘æµŠ
    clarity = 0.5*zcr_norm + 0.25*cent_norm + 0.25*roll_norm
    return float(np.clip(clarity, 0, 1))

def standardize_feature(name, val):
    # ä¸ºäº†è®©æƒé‡æ›´ç¨³ï¼Œåšä¸ªç²—ç³™æ ‡å‡†åŒ–ï¼ˆç»éªŒä¸­å¿ƒ+å°ºåº¦ï¼‰
    anchors = {
        "f0_mean": (180, 60),               # Hz
        "f0_std": (35, 20),                 # Hz
        "jitter": (0.02, 0.02),             # ratio
        "shimmer": (0.08, 0.05),            # ratio
        "loudness_db": (-15, 6),            # dBFSè¿‘ä¼¼
        "pause_ratio": (0.15, 0.15),        # 0~1
        "speaking_rate_wps": (2.2, 0.7),    # words/sec è¿‘ä¼¼
        "spectral_centroid": (2500, 1200),  # Hz
        "spectral_rolloff": (6000, 2500),   # Hz
        "noise_floor_db": (-40, 8),         # dB
        "clarity": (0.6, 0.2),              # 0~1
    }
    mu, sd = anchors.get(name, (0.0, 1.0))
    return (val - mu) / (sd + 1e-9)

def score_dimensions(feats):
    # feats: åŸå§‹ç‰©ç†é‡; å…ˆæ ‡å‡†åŒ–å†çº¿æ€§åŠ æƒ â†’ sigmoid
    xz = {k: standardize_feature(k, v) for k, v in feats.items()}
    dim_scores = {}
    for dim, wmap in WEIGHTS.items():
        z = BIASES.get(dim, 0.0)
        for fname, w in wmap.items():
            z += w * xz.get(fname, 0.0)
        dim_scores[dim] = float(sigmoid(z))
    return dim_scores

def make_karen_comment(feats, dim_scores):
    pos, neg = [], []
    for cond, text in KAREN_SNARKS:
        try:
            if cond(feats, dim_scores):
                # ç®€å•è§„åˆ™ï¼šå«æœ‰â€œPresidential/clean/want to follow/Commandingâ€å…³é”®è¯è§†ä½œæ­£å‘
                if any(k in text for k in ["Presidential", "Clean", "follow", "Commanding", "lands"]):
                    pos.append(text)
                else:
                    neg.append(text)
        except Exception:
            continue

    # è§„åˆ™ï¼šæœ€å¤šå±•ç¤º3æ¡ï¼›ä¼˜å…ˆå±•ç¤º1-2æ¡è´Ÿå‘ + 1-2æ¡æ­£å‘ï¼Œé¿å…åˆ·å±
    lines = []
    if dim_scores["authority"] >= 0.6 or dim_scores["trust"] >= 0.6:
        # é«˜åˆ†ï¼šæ­£é¢ä¸ºä¸»ï¼Œæœ€å¤š1æ¡æ¸©å’Œå»ºè®®
        lines.extend(pos[:2] or ["Strong stance."])
        if neg:
            lines.append("Refine one detail: " + neg[0])
    else:
        # ä½åˆ†ï¼šè´Ÿé¢ä¸ºä¸»ï¼Œä½†ä¿ç•™ä¸€æ¡'å‡é¼“åŠ±'
        lines.extend(neg[:2] or ["Thatâ€™s cute, but weâ€™re looking for someone with moreâ€¦ authority."])
        if pos:
            lines.append("Hidden potential: " + pos[0])

    # åŠ æ”¶æŸè¯­ï¼ˆç«é€‰å™äº‹ï¼‰
    if all(dim_scores[k] >= v for k, v in PASS_RULE.items()):
        lines.append("Campaign verdict: APPROVED. See you on the ballot.")
    else:
        lines.append("Campaign verdict: REJECTED. Rally your voice and come back.")

    return " ".join(lines[:4])


def pass_fail(dim_scores):
    ok = all(dim_scores[k] >= v for k, v in PASS_RULE.items())
    return "PASS" if ok else "FAIL"

@dataclass
class ProfileCard:
    candidate_id: str
    predicted_role: str
    voice_bias: str
    decision: str
    scores: dict
    features: dict

def build_profile_card(feats, scores, decision):
    # ç²—ç•¥ç”Ÿæˆâ€œåå¥½è§’è‰²â€ä¸â€œVoice Biasâ€æ ‡ç­¾
    role = "Assistant Personality Type"
    if scores["authority"] > 0.65 and scores["trust"] > 0.55:
        role = "Team Lead Personality Type"
    if scores["fluency"] > 0.7 and scores["clarity"] > 0.65:
        role = "Spokesperson Personality Type"

    # Voice Bias æ ‡ç­¾ï¼ˆç¤ºä¾‹ï¼‰
    bias_tags = []
    bias_tags.append("feminine" if feats["f0_mean"] > 200 else "masculine-ish")
    bias_tags.append("East-Coast Accent? (proxy)")  # è¿™é‡Œåªåšå ä½ç¬¦ï¼Œæœªæ¥å¯ç”¨æ›´å¤æ‚æ–¹æ³•ä¼°ç®—
    bias_tags.append("polite under stress" if feats["pause_ratio"] > 0.2 else "decisive pacing")

    return ProfileCard(
        candidate_id=f"#{np.random.randint(10000, 99999)}",
        predicted_role=role,
        voice_bias=" / ".join(bias_tags),
        decision=decision,
        scores=scores,
        features=feats
    )

def print_ui(scores, feats, decision, karen_text):
    # ä¼ªè£…æˆâ€œä¼ä¸šé¢è¯• AIâ€ç•Œé¢è¾“å‡º
    conf = int(round(100 * ((scores["authority"] + scores["trust"]) / 2)))
    accent_dev = abs(standardize_feature("spectral_centroid", feats["spectral_centroid"]))
    trust_index = 10 * scores["trust"]

    print("\n[ Calibrating Karenâ€¦ ]")
    for _ in range(10):
        time.sleep(0.05)
        print("â–®", end="", flush=True)
    print("\n")

    print(f"Confidence Analysis {conf}% | Accent Deviation {accent_dev:.2f} | Trust Index {trust_index:.1f}/10")
    print("-" * 72)
    for k in ["authority", "trust", "clarity", "fluency", "warmth"]:
        print(f"{k.capitalize():<10}: {scores[k]:.2f}")
    print("-" * 72)
    lamp = "ğŸŸ¢ PASS" if decision == "PASS" else "ğŸ”´ FAIL"
    print(f"Decision: {lamp}")
    print("\nKaren says:")
    print(karen_text)
    print("-" * 72)

def main():
    audio_path = sys.argv[1] if len(sys.argv) >= 2 else DEFAULT_AUDIO
    if not os.path.isfile(audio_path):
        print(f"[Error] Audio not found: {audio_path}")
        sys.exit(1)

    # è¯»å–éŸ³é¢‘
    y, sr = librosa.load(audio_path, sr=SR, mono=True)
    y = librosa.util.normalize(y)

    # ç‰¹å¾æå–
    f0_mean, f0_std, jitter = estimate_pitch(y, SR)
    loud_db = rms_db(y)
    energy = moving_energy(y, int(SR*FRAME_LEN), HOP_LENGTH)
    pause_feats = estimate_pause_features(y, SR)
    pause_ratio = pause_feats["pause_ratio"]

    speaking_rate = estimate_speaking_rate(y, SR)
    centroid, rolloff = spectral_features(y, SR)
    shimmer = estimate_shimmer(y, SR)
    clarity = estimate_clarity(y, SR)
    noise_db = estimate_noise_floor_db(y, SR)

    feats = {
        "f0_mean": f0_mean,
        "f0_std": f0_std,
        "jitter": jitter,
        "shimmer": shimmer,
        "loudness_db": loud_db,
        "pause_ratio": pause_ratio,
        "speaking_rate_wps": speaking_rate,
        "spectral_centroid": centroid,
        "spectral_rolloff": rolloff,
        "noise_floor_db": noise_db,
        "clarity": clarity,
        "pause_long_ratio": pause_feats["pause_long_ratio"],
        "pause_micro_ratio": pause_feats["pause_micro_ratio"],
        "filler_like_ratio": pause_feats["filler_like_ratio"],
        "pause_cv": pause_feats["pause_cv"],

    }

    # æ‰“åˆ†
    scores = score_dimensions(feats)
    decision = pass_fail(scores)
    karen_text = make_karen_comment(feats, scores)
    print_ui(scores, feats, decision, karen_text)

    # ç”Ÿæˆ Profile Card å¹¶ä¿å­˜
    card = build_profile_card(feats, scores, decision)
    out_dir = os.path.join(os.path.dirname(audio_path), "Output")
    os.makedirs(out_dir, exist_ok=True)
    out_json = os.path.join(out_dir, "karen_result.json")

    # âœ… æ–°å¢ï¼šnumpyâ†’Pythonç±»å‹è½¬æ¢
    def _to_py(o):
        import numpy as np
        if isinstance(o, dict):
            return {k: _to_py(v) for k, v in o.items()}
        if isinstance(o, (list, tuple)):
            return [_to_py(v) for v in o]
        if isinstance(o, (np.floating, np.integer)):
            return o.item()
        return o

    # è½¬æ¢åå†™å‡º
    out_payload = _to_py(asdict(card))
    with open(out_json, "w", encoding="utf-8") as f:
        json.dump(out_payload, f, ensure_ascii=False, indent=2)

    print(f"Profile Card saved to: {out_json}")


if __name__ == "__main__":
    main()
